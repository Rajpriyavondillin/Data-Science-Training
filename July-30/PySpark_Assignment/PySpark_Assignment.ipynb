{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Assignment – Product Sales Analysis (Intermediate)"
      ],
      "metadata": {
        "id": "hp-Hxpy8MnLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Environment Setup"
      ],
      "metadata": {
        "id": "7KUAnUu2NW7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iFxT_X_KMmeV",
        "outputId": "4805708d-36fc-45fd-aa45-785a57dfdfc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Set Environment Variables and Initialize Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ProductSalesAnalysis\").getOrCreate()\n",
        "spark.version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Load Sales Data from CSV"
      ],
      "metadata": {
        "id": "rlGOUCwmNU6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the sales.csv file\n",
        "csv_data = \"\"\"OrderID,Product,Category,Quantity,UnitPrice,Region\n",
        "1001,Mobile,Electronics,2,15000,North\n",
        "1002,Laptop,Electronics,1,55000,South\n",
        "1003,T-Shirt,Apparel,3,500,East\n",
        "1004,Jeans,Apparel,2,1200,North\n",
        "1005,TV,Electronics,1,40000,West\n",
        "1006,Shoes,Footwear,4,2000,South\n",
        "1007,Watch,Accessories,2,3000,East\n",
        "1008,Headphones,Electronics,3,2500,North\"\"\"\n",
        "\n",
        "with open(\"sales.csv\", \"w\") as file:\n",
        "    file.write(csv_data)"
      ],
      "metadata": {
        "id": "2HWpzhFlMvDb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV into PySpark DataFrame\n",
        "df = spark.read.csv(\"sales.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "uKPLhC5qMvBI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Schema and Show Top 5 Rows\n",
        "df.printSchema()\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmhdAXTcMu-o",
        "outputId": "fa7ca205-cb0a-4ac3-cd41-f71d684707d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- UnitPrice: integer (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            "\n",
            "+-------+-------+-----------+--------+---------+------+\n",
            "|OrderID|Product|   Category|Quantity|UnitPrice|Region|\n",
            "+-------+-------+-----------+--------+---------+------+\n",
            "|   1001| Mobile|Electronics|       2|    15000| North|\n",
            "|   1002| Laptop|Electronics|       1|    55000| South|\n",
            "|   1003|T-Shirt|    Apparel|       3|      500|  East|\n",
            "|   1004|  Jeans|    Apparel|       2|     1200| North|\n",
            "|   1005|     TV|Electronics|       1|    40000|  West|\n",
            "+-------+-------+-----------+--------+---------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Business Questions"
      ],
      "metadata": {
        "id": "7eZ-zdPhNSbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Add a new column TotalPrice = Quantity × UnitPrice\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"TotalPrice\", col(\"Quantity\") * col(\"UnitPrice\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pao_lh1zMu5I",
        "outputId": "3e9fb30b-c022-451c-830f-a419fde3b626"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----------+--------+---------+------+----------+\n",
            "|OrderID|   Product|   Category|Quantity|UnitPrice|Region|TotalPrice|\n",
            "+-------+----------+-----------+--------+---------+------+----------+\n",
            "|   1001|    Mobile|Electronics|       2|    15000| North|     30000|\n",
            "|   1002|    Laptop|Electronics|       1|    55000| South|     55000|\n",
            "|   1003|   T-Shirt|    Apparel|       3|      500|  East|      1500|\n",
            "|   1004|     Jeans|    Apparel|       2|     1200| North|      2400|\n",
            "|   1005|        TV|Electronics|       1|    40000|  West|     40000|\n",
            "|   1006|     Shoes|   Footwear|       4|     2000| South|      8000|\n",
            "|   1007|     Watch|Accessories|       2|     3000|  East|      6000|\n",
            "|   1008|Headphones|Electronics|       3|     2500| North|      7500|\n",
            "+-------+----------+-----------+--------+---------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Total revenue generated across all regions.\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "\n",
        "df.agg(sum(\"TotalPrice\").alias(\"TotalRevenue\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PmU2U04Mu16",
        "outputId": "1c7128d8-ded6-4718-af87-95d335e95ed3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|TotalRevenue|\n",
            "+------------+\n",
            "|      150400|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Category-wise revenue sorted in descending order.\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "category_revenue = df.groupBy(\"Category\").agg(sum(\"TotalPrice\").alias(\"TotalRevenue\"))\n",
        "category_revenue = category_revenue.orderBy(desc(\"TotalRevenue\"))\n",
        "category_revenue.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkPF0U6YMuzp",
        "outputId": "228282cc-d1cb-493c-f983-2a480f36e3e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|   Category|TotalRevenue|\n",
            "+-----------+------------+\n",
            "|Electronics|      132500|\n",
            "|   Footwear|        8000|\n",
            "|Accessories|        6000|\n",
            "|    Apparel|        3900|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Region with the highest number of orders\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "region_order_count = df.groupBy(\"Region\").count()\n",
        "region_order_count = region_order_count.orderBy(desc(\"count\"))\n",
        "region_order_count.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66n29zI6M3RW",
        "outputId": "bb6f7ff1-c3cc-412b-bae3-a28a697491c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Region|count|\n",
            "+------+-----+\n",
            "| North|    3|\n",
            "+------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Average Unit Price per Category\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "average_price_per_category = df.groupBy(\"Category\").agg(avg(\"UnitPrice\").alias(\"AverageUnitPrice\"))\n",
        "average_price_per_category.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdjwseEaM3Or",
        "outputId": "6ca4a4d9-8c60-4771-ebf1-5f3bcb042ca9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------------+\n",
            "|   Category|AverageUnitPrice|\n",
            "+-----------+----------------+\n",
            "|    Apparel|           850.0|\n",
            "|Electronics|         28125.0|\n",
            "|   Footwear|          2000.0|\n",
            "|Accessories|          3000.0|\n",
            "+-----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. All orders where TotalPrice is more than 30,000\n",
        "filtered_orders = df.filter(col(\"TotalPrice\") > 30000)\n",
        "filtered_orders.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPNrNmujM3MB",
        "outputId": "528fe250-366f-4aa3-fb89-13f6b37ba016"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----------+--------+---------+------+----------+\n",
            "|OrderID|Product|   Category|Quantity|UnitPrice|Region|TotalPrice|\n",
            "+-------+-------+-----------+--------+---------+------+----------+\n",
            "|   1002| Laptop|Electronics|       1|    55000| South|     55000|\n",
            "|   1005|     TV|Electronics|       1|    40000|  West|     40000|\n",
            "+-------+-------+-----------+--------+---------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Data Transformations"
      ],
      "metadata": {
        "id": "C4yTfMU5NOhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a new column HighValueOrder which is \"Yes\" if TotalPrice > 20,000, else \"No\" .\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "df = df.withColumn(\"HighValueOrder\", when(col(\"TotalPrice\") > 20000, \"Yes\").otherwise(\"No\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsVGMoz8M3JO",
        "outputId": "8ab12bec-f324-4a1d-ece1-436fb8f59101"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----------+--------+---------+------+----------+--------------+\n",
            "|OrderID|   Product|   Category|Quantity|UnitPrice|Region|TotalPrice|HighValueOrder|\n",
            "+-------+----------+-----------+--------+---------+------+----------+--------------+\n",
            "|   1001|    Mobile|Electronics|       2|    15000| North|     30000|           Yes|\n",
            "|   1002|    Laptop|Electronics|       1|    55000| South|     55000|           Yes|\n",
            "|   1003|   T-Shirt|    Apparel|       3|      500|  East|      1500|            No|\n",
            "|   1004|     Jeans|    Apparel|       2|     1200| North|      2400|            No|\n",
            "|   1005|        TV|Electronics|       1|    40000|  West|     40000|           Yes|\n",
            "|   1006|     Shoes|   Footwear|       4|     2000| South|      8000|            No|\n",
            "|   1007|     Watch|Accessories|       2|     3000|  East|      6000|            No|\n",
            "|   1008|Headphones|Electronics|       3|     2500| North|      7500|            No|\n",
            "+-------+----------+-----------+--------+---------+------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Filter and display all high-value orders in the North region.\n",
        "high_value_orders_north = df.filter((col(\"TotalPrice\") > 20000) & (col(\"Region\") == \"North\"))\n",
        "high_value_orders_north.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKBBJefLM3G3",
        "outputId": "99292e9d-0182-430b-da29-291b59eb41df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----------+--------+---------+------+----------+--------------+\n",
            "|OrderID|Product|   Category|Quantity|UnitPrice|Region|TotalPrice|HighValueOrder|\n",
            "+-------+-------+-----------+--------+---------+------+----------+--------------+\n",
            "|   1001| Mobile|Electronics|       2|    15000| North|     30000|           Yes|\n",
            "+-------+-------+-----------+--------+---------+------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Count how many high-value orders exist per region.\n",
        "high_value_orders_per_region = df.filter(col(\"HighValueOrder\") == \"Yes\").groupBy(\"Region\").count()\n",
        "high_value_orders_per_region.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HqkuocTM3EX",
        "outputId": "fd44cdd3-af6a-447c-9dd8-e050c259f251"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Region|count|\n",
            "+------+-----+\n",
            "| South|    1|\n",
            "|  West|    1|\n",
            "| North|    1|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Save Results"
      ],
      "metadata": {
        "id": "cvErVHIcNJ5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the transformed DataFrame as a CSV file named high_value_orders.csv with headers.\n",
        "# Filter high-value orders\n",
        "high_value_orders = df.filter(df[\"HighValueOrder\"] == \"Yes\")\n",
        "\n",
        "# Save to CSV\n",
        "high_value_orders.coalesce(1).write.mode(\"overwrite\").option(\"header\",True).csv(\"high_value_orders\")\n"
      ],
      "metadata": {
        "id": "bh9_sbj6M3B4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download CSV from Google Colab"
      ],
      "metadata": {
        "id": "Eow4a_YaNBiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import glob\n",
        "\n",
        "# Find the part file created by Spark\n",
        "output_file=glob.glob(\"high_value_orders/part-*.csv\")[0]\n",
        "\n",
        "# Copy to more accessible path\n",
        "shutil.copy(output_file, \"high_value_orders.csv\")\n",
        "\n",
        "# Download the csv file\n",
        "from google.colab import files\n",
        "files.download(\"high_value_orders.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8D1WHBKpM2_X",
        "outputId": "1ade67f5-c37a-4abe-8bbe-d6f4440b4b26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d932b99-43f2-421a-8140-d241d1d33ed0\", \"high_value_orders.csv\", 216)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}