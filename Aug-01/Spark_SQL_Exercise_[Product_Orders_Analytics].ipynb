{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark SQL Exercise Set – Product Orders Analytics\n",
        "Dataset Theme: E-Commerce Orders\n",
        "\n",
        "Preparation Instructions"
      ],
      "metadata": {
        "id": "fgB96WU0d-4k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F8SVzNL9d-QX"
      },
      "outputs": [],
      "source": [
        "# 1. Create a PySpark DataFrame with the following schema:\n",
        "from pyspark.sql import SparkSession, Row\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"ProductOrdersAnalytics\").getOrCreate()\n",
        "\n",
        "# 2. Sample at least 12 rows across multiple categories:\n",
        "# \"Electronics\" , \"Clothing\" , \"Furniture\" , \"Books\"\n",
        "data = [\n",
        "    Row(OrderID=1, CustomerName=\"Alice\", Product=\"Laptop\", Category=\"Electronics\", Quantity=2, UnitPrice=50000, OrderDate=\"2023-01-05\"),\n",
        "    Row(OrderID=2, CustomerName=\"Bob\", Product=\"Shirt\", Category=\"Clothing\", Quantity=3, UnitPrice=1200, OrderDate=\"2023-01-12\"),\n",
        "    Row(OrderID=3, CustomerName=\"Charlie\", Product=\"Bookshelf\", Category=\"Furniture\", Quantity=1, UnitPrice=7000, OrderDate=\"2023-02-10\"),\n",
        "    Row(OrderID=4, CustomerName=\"Diana\", Product=\"Headphones\", Category=\"Electronics\", Quantity=1, UnitPrice=3000, OrderDate=\"2023-03-15\"),\n",
        "    Row(OrderID=5, CustomerName=\"Eva\", Product=\"Notebook\", Category=\"Books\", Quantity=5, UnitPrice=200, OrderDate=\"2023-01-20\"),\n",
        "    Row(OrderID=6, CustomerName=\"Frank\", Product=\"Sofa\", Category=\"Furniture\", Quantity=2, UnitPrice=25000, OrderDate=\"2023-02-25\"),\n",
        "    Row(OrderID=7, CustomerName=\"George\", Product=\"Camera\", Category=\"Electronics\", Quantity=2, UnitPrice=40000, OrderDate=\"2023-04-01\"),\n",
        "    Row(OrderID=8, CustomerName=\"Hannah\", Product=\"Dress\", Category=\"Clothing\", Quantity=1, UnitPrice=3000, OrderDate=\"2023-03-09\"),\n",
        "    Row(OrderID=9, CustomerName=\"Ivy\", Product=\"Textbook\", Category=\"Books\", Quantity=2, UnitPrice=800, OrderDate=\"2023-01-11\"),\n",
        "    Row(OrderID=10, CustomerName=\"Jack\", Product=\"Dining Table\", Category=\"Furniture\", Quantity=1, UnitPrice=15000, OrderDate=\"2023-03-22\"),\n",
        "    Row(OrderID=11, CustomerName=\"Karan\", Product=\"Jeans\", Category=\"Clothing\", Quantity=4, UnitPrice=1500, OrderDate=\"2023-04-13\"),\n",
        "    Row(OrderID=12, CustomerName=\"Liam\", Product=\"Smartphone\", Category=\"Electronics\", Quantity=1, UnitPrice=60000, OrderDate=\"2023-02-05\")\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# 3. Create:\n",
        "# A local temporary view: \"orders_local\"\n",
        "# A global temporary view: \"orders_global\"\n",
        "df.createOrReplaceTempView(\"orders_local\")\n",
        "df.createOrReplaceGlobalTempView(\"orders_global\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A: Local View – orders_local"
      ],
      "metadata": {
        "id": "f4ai-BrUekXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. List all orders placed for \"Electronics\" with a Quantity of 2 or more.\n",
        "2. Calculate TotalAmount (Quantity × UnitPrice) for each order.\n",
        "3. Show the total number of orders per Category .\n",
        "4. List orders placed in \"January 2023\" only.\n",
        "5. Show the average UnitPrice per category.\n",
        "6. Find the order with the highest total amount.\n",
        "7. Drop the local view and try querying it again."
      ],
      "metadata": {
        "id": "_SxViKbXen4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. List all orders placed for \"Electronics\" with a Quantity of 2 or more.\n",
        "spark.sql(\"\"\"\n",
        "SELECT * FROM orders_local\n",
        "WHERE Category = 'Electronics' AND Quantity >= 2\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RscIvFMieiLz",
        "outputId": "296e3152-ed84-40b5-8032-ece46ce70d95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "|      1|       Alice| Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      7|      George| Camera|Electronics|       2|    40000|2023-04-01|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Calculate TotalAmount (Quantity × UnitPrice) for each order.\n",
        "spark.sql(\"\"\"\n",
        "SELECT *, (Quantity * UnitPrice) AS TotalAmount\n",
        "FROM orders_local\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FshlV34ezsg",
        "outputId": "cbf44601-f41b-4528-ee2c-b81e99613a58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|     Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+-----------+\n",
            "|      1|       Alice|      Laptop|Electronics|       2|    50000|2023-01-05|     100000|\n",
            "|      2|         Bob|       Shirt|   Clothing|       3|     1200|2023-01-12|       3600|\n",
            "|      3|     Charlie|   Bookshelf|  Furniture|       1|     7000|2023-02-10|       7000|\n",
            "|      4|       Diana|  Headphones|Electronics|       1|     3000|2023-03-15|       3000|\n",
            "|      5|         Eva|    Notebook|      Books|       5|      200|2023-01-20|       1000|\n",
            "|      6|       Frank|        Sofa|  Furniture|       2|    25000|2023-02-25|      50000|\n",
            "|      7|      George|      Camera|Electronics|       2|    40000|2023-04-01|      80000|\n",
            "|      8|      Hannah|       Dress|   Clothing|       1|     3000|2023-03-09|       3000|\n",
            "|      9|         Ivy|    Textbook|      Books|       2|      800|2023-01-11|       1600|\n",
            "|     10|        Jack|Dining Table|  Furniture|       1|    15000|2023-03-22|      15000|\n",
            "|     11|       Karan|       Jeans|   Clothing|       4|     1500|2023-04-13|       6000|\n",
            "|     12|        Liam|  Smartphone|Electronics|       1|    60000|2023-02-05|      60000|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Show the total number of orders per Category .\n",
        "spark.sql(\"\"\"\n",
        "SELECT Category, COUNT(*) AS TotalOrders\n",
        "FROM orders_local\n",
        "GROUP BY Category\n",
        "\"\"\").show()\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g7qYodPfKho",
        "outputId": "3f250e6f-cfbb-4da1-bf1b-76b7c9295b32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|   Category|TotalOrders|\n",
            "+-----------+-----------+\n",
            "|Electronics|          4|\n",
            "|   Clothing|          3|\n",
            "|      Books|          2|\n",
            "|  Furniture|          3|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. List orders placed in \"January 2023\" only.\n",
        "spark.sql(\"\"\"\n",
        "SELECT * FROM orders_local\n",
        "WHERE OrderDate LIKE '2023-01%'\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xMI5B6xfP4u",
        "outputId": "805a4da2-1940-49ab-87d8-0207b098e8b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName| Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+--------+-----------+--------+---------+----------+\n",
            "|      1|       Alice|  Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      2|         Bob|   Shirt|   Clothing|       3|     1200|2023-01-12|\n",
            "|      5|         Eva|Notebook|      Books|       5|      200|2023-01-20|\n",
            "|      9|         Ivy|Textbook|      Books|       2|      800|2023-01-11|\n",
            "+-------+------------+--------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Show the average UnitPrice per category.\n",
        "spark.sql(\"\"\"\n",
        "SELECT Category, AVG(UnitPrice) AS AvgUnitPrice\n",
        "FROM orders_local\n",
        "GROUP BY Category\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFUtV6-3fS0D",
        "outputId": "3e7edbc8-a2ef-41ff-e00d-c81177accb96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|   Category|      AvgUnitPrice|\n",
            "+-----------+------------------+\n",
            "|Electronics|           38250.0|\n",
            "|   Clothing|            1900.0|\n",
            "|      Books|             500.0|\n",
            "|  Furniture|15666.666666666666|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Find the order with the highest total amount.\n",
        "spark.sql(\"\"\"\n",
        "SELECT *, (Quantity * UnitPrice) AS TotalAmount\n",
        "FROM orders_local\n",
        "ORDER BY TotalAmount DESC\n",
        "LIMIT 1\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfS0Lx7HfVZJ",
        "outputId": "d6d2f843-68df-4ba0-f7b2-921519a6f90b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|      1|       Alice| Laptop|Electronics|       2|    50000|2023-01-05|     100000|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Drop the local view and try querying it again.\n",
        "spark.catalog.dropTempView(\"orders_local\")\n",
        "\n",
        "# Try - querying it again, This will raise AnalysisException\n",
        "spark.sql(\"SELECT * FROM orders_local\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "kLW3qKNCfXwJ",
        "outputId": "5a292f29-4611-4fb0-abc4-9f986b38c334"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [orders_local], [], false\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1611073114.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Try - querying it again, This will raise AnalysisException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM orders_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [orders_local], [], false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B: Global View – orders_global"
      ],
      "metadata": {
        "id": "VnPptEEqfztU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Display all \"Furniture\" orders with TotalAmount above 10,000.\n",
        "2. Create a column called DiscountFlag :\n",
        "\n",
        "    Mark \"Yes\" if Quantity > 3\n",
        "    \n",
        "    Otherwise \"No\"\n",
        "3. List customers who ordered more than 1 product type (Hint: use GROUP BY and\n",
        "HAVING).\n",
        "4. Count number of orders per month across the dataset.\n",
        "5. Rank all products by total quantity sold across all orders using a window\n",
        "function.\n",
        "6. Run a query using a new SparkSession and the global view."
      ],
      "metadata": {
        "id": "yeINgg2cf3oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Display all \"Furniture\" orders with TotalAmount above 10,000.\n",
        "spark.sql(\"\"\"\n",
        "SELECT *, (Quantity * UnitPrice) AS TotalAmount\n",
        "FROM global_temp.orders_global\n",
        "WHERE Category = 'Furniture' AND (Quantity * UnitPrice) > 10000\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPV9kY2af848",
        "outputId": "52cbdf3b-0a29-4720-b560-dc37fbfe547f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------+---------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|     Product| Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+------------+---------+--------+---------+----------+-----------+\n",
            "|      6|       Frank|        Sofa|Furniture|       2|    25000|2023-02-25|      50000|\n",
            "|     10|        Jack|Dining Table|Furniture|       1|    15000|2023-03-22|      15000|\n",
            "+-------+------------+------------+---------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a column called DiscountFlag :\n",
        "    # Mark \"Yes\" if Quantity > 3\n",
        "    # Otherwise \"No\"\n",
        "spark.sql(\"\"\"\n",
        "SELECT *,\n",
        "    CASE\n",
        "        WHEN Quantity > 3 THEN 'Yes'\n",
        "        ELSE 'No'\n",
        "    END AS DiscountFlag\n",
        "FROM global_temp.orders_global\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPku3lxPgHid",
        "outputId": "708c0455-3e62-471c-db5d-469d4af27bf3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------+-----------+--------+---------+----------+------------+\n",
            "|OrderID|CustomerName|     Product|   Category|Quantity|UnitPrice| OrderDate|DiscountFlag|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+------------+\n",
            "|      1|       Alice|      Laptop|Electronics|       2|    50000|2023-01-05|          No|\n",
            "|      2|         Bob|       Shirt|   Clothing|       3|     1200|2023-01-12|          No|\n",
            "|      3|     Charlie|   Bookshelf|  Furniture|       1|     7000|2023-02-10|          No|\n",
            "|      4|       Diana|  Headphones|Electronics|       1|     3000|2023-03-15|          No|\n",
            "|      5|         Eva|    Notebook|      Books|       5|      200|2023-01-20|         Yes|\n",
            "|      6|       Frank|        Sofa|  Furniture|       2|    25000|2023-02-25|          No|\n",
            "|      7|      George|      Camera|Electronics|       2|    40000|2023-04-01|          No|\n",
            "|      8|      Hannah|       Dress|   Clothing|       1|     3000|2023-03-09|          No|\n",
            "|      9|         Ivy|    Textbook|      Books|       2|      800|2023-01-11|          No|\n",
            "|     10|        Jack|Dining Table|  Furniture|       1|    15000|2023-03-22|          No|\n",
            "|     11|       Karan|       Jeans|   Clothing|       4|     1500|2023-04-13|         Yes|\n",
            "|     12|        Liam|  Smartphone|Electronics|       1|    60000|2023-02-05|          No|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. List customers who ordered more than 1 product type (Hint: use GROUP BY and HAVING).\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW filtered_orders AS\n",
        "SELECT * FROM global_temp.orders_global\n",
        "WHERE Category != 'Clothing'\n",
        "\"\"\")\n",
        "spark.sql(\"SELECT * FROM filtered_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyrKeC5vgWBG",
        "outputId": "cd03af5f-0861-41b1-c6f3-2d1c52bd666f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|     Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+\n",
            "|      1|       Alice|      Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      3|     Charlie|   Bookshelf|  Furniture|       1|     7000|2023-02-10|\n",
            "|      4|       Diana|  Headphones|Electronics|       1|     3000|2023-03-15|\n",
            "|      5|         Eva|    Notebook|      Books|       5|      200|2023-01-20|\n",
            "|      6|       Frank|        Sofa|  Furniture|       2|    25000|2023-02-25|\n",
            "|      7|      George|      Camera|Electronics|       2|    40000|2023-04-01|\n",
            "|      9|         Ivy|    Textbook|      Books|       2|      800|2023-01-11|\n",
            "|     10|        Jack|Dining Table|  Furniture|       1|    15000|2023-03-22|\n",
            "|     12|        Liam|  Smartphone|Electronics|       1|    60000|2023-02-05|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Count number of orders per month across the dataset.\n",
        "spark.sql(\"\"\"\n",
        "SELECT MONTH(OrderDate) AS Month, COUNT(*) AS OrderCount\n",
        "FROM global_temp.orders_global\n",
        "GROUP BY MONTH(OrderDate)\n",
        "ORDER BY MONTH(OrderDate)\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAnqV91tgYe_",
        "outputId": "2ff39848-c217-4d73-d816-b34c61d7759e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|Month|OrderCount|\n",
            "+-----+----------+\n",
            "|    1|         4|\n",
            "|    2|         3|\n",
            "|    3|         3|\n",
            "|    4|         2|\n",
            "+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Rank all products by total quantity sold across all orders using a window function.\n",
        "spark.sql(\"\"\"\n",
        "SELECT Product, TotalQuantity,\n",
        "       RANK() OVER (ORDER BY TotalQuantity DESC) AS Rank\n",
        "FROM (\n",
        "    SELECT Product, SUM(Quantity) AS TotalQuantity\n",
        "    FROM global_temp.orders_global\n",
        "    GROUP BY Product\n",
        ")\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYI9byzNgbMi",
        "outputId": "7b6a0046-23c8-4f07-bd14-7a330b077eed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+----+\n",
            "|     Product|TotalQuantity|Rank|\n",
            "+------------+-------------+----+\n",
            "|    Notebook|            5|   1|\n",
            "|       Jeans|            4|   2|\n",
            "|       Shirt|            3|   3|\n",
            "|      Laptop|            2|   4|\n",
            "|        Sofa|            2|   4|\n",
            "|    Textbook|            2|   4|\n",
            "|      Camera|            2|   4|\n",
            "|   Bookshelf|            1|   8|\n",
            "|  Headphones|            1|   8|\n",
            "|       Dress|            1|   8|\n",
            "|Dining Table|            1|   8|\n",
            "|  Smartphone|            1|   8|\n",
            "+------------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Run a query using a new SparkSession and the global view.\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create new SparkSession\n",
        "new_spark = SparkSession.builder.appName(\"NewSession\").getOrCreate()\n",
        "\n",
        "# Access global temp view from new session\n",
        "new_spark.sql(\"\"\"\n",
        "SELECT DISTINCT Category\n",
        "FROM global_temp.orders_global\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jgFqAt7gduE",
        "outputId": "dbdf0691-ae61-447f-e264-9e6166ecf60c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|   Category|\n",
            "+-----------+\n",
            "|Electronics|\n",
            "|   Clothing|\n",
            "|      Books|\n",
            "|  Furniture|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus Challenges"
      ],
      "metadata": {
        "id": "qYx0TepnggY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Save a filtered subset (only \"Books\" category) as a new global temp view.\n",
        "2. Find the most purchased product per category.\n",
        "3. Create a view that excludes all \"Clothing\" orders and call it\n",
        "\"filtered_orders\" ."
      ],
      "metadata": {
        "id": "nEsUJj96gjuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save a filtered subset (only \"Books\" category) as a new global temp view.\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE GLOBAL TEMP VIEW books_only AS\n",
        "SELECT *\n",
        "FROM global_temp.orders_global\n",
        "WHERE Category = 'Books'\n",
        "\"\"\")\n",
        "spark.sql(\"SELECT * FROM global_temp.books_only\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uUcnJtFglha",
        "outputId": "eba93c70-ab6e-4330-b354-4b87463c3e58"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------+--------+--------+---------+----------+\n",
            "|OrderID|CustomerName| Product|Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+--------+--------+--------+---------+----------+\n",
            "|      5|         Eva|Notebook|   Books|       5|      200|2023-01-20|\n",
            "|      9|         Ivy|Textbook|   Books|       2|      800|2023-01-11|\n",
            "+-------+------------+--------+--------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Find the most purchased product per category.\n",
        "spark.sql(\"\"\"\n",
        "SELECT Category, Product, TotalQty FROM (\n",
        "    SELECT Category, Product, SUM(Quantity) AS TotalQty,\n",
        "           RANK() OVER (PARTITION BY Category ORDER BY SUM(Quantity) DESC) AS rk\n",
        "    FROM global_temp.orders_global\n",
        "    GROUP BY Category, Product\n",
        ")\n",
        "WHERE rk = 1\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_3zrQmsgoJp",
        "outputId": "5d9d9ff7-0d91-4723-dbbb-0181ba61ca52"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+--------+\n",
            "|   Category| Product|TotalQty|\n",
            "+-----------+--------+--------+\n",
            "|      Books|Notebook|       5|\n",
            "|   Clothing|   Jeans|       4|\n",
            "|Electronics|  Laptop|       2|\n",
            "|Electronics|  Camera|       2|\n",
            "|  Furniture|    Sofa|       2|\n",
            "+-----------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create a view that excludes all \"Clothing\" orders and call it \"filtered_orders\" .\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW filtered_orders AS\n",
        "SELECT *\n",
        "FROM global_temp.orders_global\n",
        "WHERE Category != 'Clothing'\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM filtered_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cOXRILFgriT",
        "outputId": "7ca25f82-8876-46db-aed6-a8644147263f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|     Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+\n",
            "|      1|       Alice|      Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|      3|     Charlie|   Bookshelf|  Furniture|       1|     7000|2023-02-10|\n",
            "|      4|       Diana|  Headphones|Electronics|       1|     3000|2023-03-15|\n",
            "|      5|         Eva|    Notebook|      Books|       5|      200|2023-01-20|\n",
            "|      6|       Frank|        Sofa|  Furniture|       2|    25000|2023-02-25|\n",
            "|      7|      George|      Camera|Electronics|       2|    40000|2023-04-01|\n",
            "|      9|         Ivy|    Textbook|      Books|       2|      800|2023-01-11|\n",
            "|     10|        Jack|Dining Table|  Furniture|       1|    15000|2023-03-22|\n",
            "|     12|        Liam|  Smartphone|Electronics|       1|    60000|2023-02-05|\n",
            "+-------+------------+------------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}