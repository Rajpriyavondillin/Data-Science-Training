{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. PySpark Setup & Initialization\n",
        "\n",
        "Exercise 1.1 – Setup Spark:\n",
        "\n",
        "    Initialize SparkSession with:"
      ],
      "metadata": {
        "id": "aAGVtyJK9bOC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X7XjmQ46yM_J"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "  .appName(\"BotCampus Intermediate Session\") \\\n",
        "  .master(\"local[*]\") \\\n",
        "  .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.2 – Load starter data:"
      ],
      "metadata": {
        "id": "SfYlDb7M9m1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Ananya\", \"Bangalore\", 24),\n",
        "  (\"Ravi\", \"Hyderabad\", 28),\n",
        "  (\"Kavya\", \"Delhi\", 22),\n",
        "  (\"Meena\", \"Chennai\", 25)\n",
        "]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5RwI6e5ycX2",
        "outputId": "a6493b3e-3c76-4475-a8d5-253f49cf49ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Ananya|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. RDDs & Transformations"
      ],
      "metadata": {
        "id": "gQsvPULo9r4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2.1 – Create RDD from feedback:"
      ],
      "metadata": {
        "id": "SVXvfG7J9s_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "  \"Ravi from Bangalore loved the mobile app\",\n",
        "  \"Meena from Delhi reported poor response time\",\n",
        "  \"Ajay from Pune liked the delivery speed\",\n",
        "  \"Ananya from Hyderabad had an issue with UI\",\n",
        "  \"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "O2eFGmBGyvTi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "\n",
        "\n",
        "    Count total number of words.\n",
        "\n",
        "    Find top 3 most common words.\n",
        "\n",
        "    Remove stop words ( from , with , the , etc.).\n",
        "\n",
        "    Create a dictionary of word → count.\n",
        "\n"
      ],
      "metadata": {
        "id": "w03iMhOM9xdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total number of words.\n",
        "total_words = feedback.flatMap(lambda x: x.split()).count()\n",
        "print(\"Total number of words:\", total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MONKnA1Cyzii",
        "outputId": "b96dc52d-69bc-493c-cd02-c0bb775be881"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find top 3 most common words.\n",
        "from operator import add\n",
        "word_counts = feedback.flatMap(lambda x: x.lower().split()) \\\n",
        "                      .map(lambda word: (word, 1)) \\\n",
        "                      .reduceByKey(add)\n",
        "\n",
        "top_3 = word_counts.takeOrdered(3, key=lambda x: -x[1])\n",
        "print(\"Top 3 words:\", top_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRpx7Q3HzPci",
        "outputId": "84dc6874-133a-48ea-9beb-248793843e3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 words: [('from', 5), ('the', 2), ('loved', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words ( from , with , the , etc.).\n",
        "stop_words = {\"from\", \"with\", \"the\", \"an\", \"had\", \"of\"}\n",
        "filtered_words = word_counts.filter(lambda x: x[0] not in stop_words)\n",
        "print(\"Filtered word counts:\", filtered_words.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRKNKFc8zS_f",
        "outputId": "9ef6bdbb-9904-45fc-afd9-65b3b2215341"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered word counts: [('loved', 1), ('app', 1), ('poor', 1), ('response', 1), ('liked', 1), ('speed', 1), ('ananya', 1), ('issue', 1), ('rohit', 1), ('mumbai', 1), ('positive', 1), ('feedback', 1), ('ravi', 1), ('bangalore', 1), ('mobile', 1), ('meena', 1), ('delhi', 1), ('reported', 1), ('time', 1), ('ajay', 1), ('pune', 1), ('delivery', 1), ('hyderabad', 1), ('ui', 1), ('gave', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of word → count.\n",
        "word_dict = dict(filtered_words.collect())\n",
        "print(\"Word count dictionary:\", word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-26vbbf0zVJb",
        "outputId": "a7597227-56d5-45fd-fdf2-7cd65acc0515"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word count dictionary: {'loved': 1, 'app': 1, 'poor': 1, 'response': 1, 'liked': 1, 'speed': 1, 'ananya': 1, 'issue': 1, 'rohit': 1, 'mumbai': 1, 'positive': 1, 'feedback': 1, 'ravi': 1, 'bangalore': 1, 'mobile': 1, 'meena': 1, 'delhi': 1, 'reported': 1, 'time': 1, 'ajay': 1, 'pune': 1, 'delivery': 1, 'hyderabad': 1, 'ui': 1, 'gave': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. DataFrames – Transformations"
      ],
      "metadata": {
        "id": "JbRxCcgf9_iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3.1 – Create exam_scores DataFrame:"
      ],
      "metadata": {
        "id": "2auqihNm-ApY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [\n",
        "  (\"Ravi\", \"Math\", 88),\n",
        "  (\"Ananya\", \"Science\", 92),\n",
        "  (\"Kavya\", \"English\", 79),\n",
        "  (\"Ravi\", \"English\", 67),\n",
        "  (\"Neha\", \"Math\", 94),\n",
        "  (\"Meena\", \"Science\", 85)\n",
        "]\n",
        "columns = [\"name\", \"subject\", \"score\"]\n",
        "df_scores = spark.createDataFrame(scores, columns)"
      ],
      "metadata": {
        "id": "O3i17V4yzjzw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "    Add grade column ( >=90 → A, 80-89 → B, 70-79 → C, else D).\n",
        "\n",
        "    Group by subject, find average score.\n",
        "\n",
        "    Use when and otherwise to classify subject difficulty ( Math/Science =\n",
        "    Difficult).\n",
        "\n",
        "    Rank students per subject using Window function.\n",
        "\n",
        "    Apply UDF to format names (e.g., make all uppercase)."
      ],
      "metadata": {
        "id": "gWqd-gV9-D7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add grade column ( >=90 → A, 80-89 → B, 70-79 → C, else D).\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "df_scores = df_scores.withColumn(\n",
        "    \"grade\",\n",
        "    when(df_scores.score >= 90, \"A\")\n",
        "    .when(df_scores.score >= 80, \"B\")\n",
        "    .when(df_scores.score >= 70, \"C\")\n",
        "    .otherwise(\"D\")\n",
        ")\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOoA4Qd9zxbW",
        "outputId": "92a2ed3f-52d1-42bf-a5c9-b8217f6a4f4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+\n",
            "|  name|subject|score|grade|\n",
            "+------+-------+-----+-----+\n",
            "|  Ravi|   Math|   88|    B|\n",
            "|Ananya|Science|   92|    A|\n",
            "| Kavya|English|   79|    C|\n",
            "|  Ravi|English|   67|    D|\n",
            "|  Neha|   Math|   94|    A|\n",
            "| Meena|Science|   85|    B|\n",
            "+------+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by subject, find average score.\n",
        "df_scores.groupBy(\"subject\").avg(\"score\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiCPEyODz5hf",
        "outputId": "e3c5fd0e-6267-4c40-95f4-3fe64b3ff068"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|subject|avg(score)|\n",
            "+-------+----------+\n",
            "|Science|      88.5|\n",
            "|   Math|      91.0|\n",
            "|English|      73.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use when and otherwise to classify subject difficulty ( Math/Science = Difficult).\n",
        "df_scores = df_scores.withColumn(\n",
        "    \"difficulty\",\n",
        "    when(df_scores.subject.isin(\"Math\", \"Science\"), \"Difficult\").otherwise(\"Easy\")\n",
        ")\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncOEE6qRz-1Y",
        "outputId": "ac6b0207-bab6-41ba-81d2-fec0a0697e3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+\n",
            "|  name|subject|score|grade|difficulty|\n",
            "+------+-------+-----+-----+----------+\n",
            "|  Ravi|   Math|   88|    B| Difficult|\n",
            "|Ananya|Science|   92|    A| Difficult|\n",
            "| Kavya|English|   79|    C|      Easy|\n",
            "|  Ravi|English|   67|    D|      Easy|\n",
            "|  Neha|   Math|   94|    A| Difficult|\n",
            "| Meena|Science|   85|    B| Difficult|\n",
            "+------+-------+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank students per subject using Window function.\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "\n",
        "windowSpec = Window.partitionBy(\"subject\").orderBy(df_scores.score.desc())\n",
        "\n",
        "df_scores = df_scores.withColumn(\"rank\", rank().over(windowSpec))\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYRDrLKN0HXP",
        "outputId": "7aba2661-957a-470b-f15f-446d4542efd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+\n",
            "|  name|subject|score|grade|difficulty|rank|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "| Kavya|English|   79|    C|      Easy|   1|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|\n",
            "| Meena|Science|   85|    B| Difficult|   2|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply UDF to format names (e.g., make all uppercase).\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def upper_case(name):\n",
        "    return name.upper()\n",
        "\n",
        "upper_udf = udf(upper_case, StringType())\n",
        "\n",
        "df_scores = df_scores.withColumn(\"name_upper\", upper_udf(df_scores.name))\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JP68r8v0KbY",
        "outputId": "fd797c4e-94e2-4d21-adc2-9aa4db0f37b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+----------+\n",
            "|  name|subject|score|grade|difficulty|rank|name_upper|\n",
            "+------+-------+-----+-----+----------+----+----------+\n",
            "| Kavya|English|   79|    C|      Easy|   1|     KAVYA|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|      RAVI|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|      NEHA|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|      RAVI|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|    ANANYA|\n",
            "| Meena|Science|   85|    B| Difficult|   2|     MEENA|\n",
            "+------+-------+-----+-----+----------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ingest CSV & JSON – Save to Parquet"
      ],
      "metadata": {
        "id": "xIsZUJJr-M1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 1: CSV file: students.csv\n",
        "Dataset 2: JSON file employee_nested.json"
      ],
      "metadata": {
        "id": "h23GTMCl-OWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "    Load both datasets into PySpark.\n",
        "\n",
        "    Print schema and infer nested structure.\n",
        "\n",
        "    Flatten the JSON (use explode , select , alias ).\n",
        "\n",
        "    Convert both to Parquet and write to /tmp/output ."
      ],
      "metadata": {
        "id": "1QyDLm65-T4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "nPC5iPol1thy",
        "outputId": "93008936-a215-4fdf-e32e-9a1090ccd9d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fbe9dc4-d0e6-4c97-a097-0e047a3a727e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fbe9dc4-d0e6-4c97-a097-0e047a3a727e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving employee_nested.json to employee_nested.json\n",
            "Saving students.csv to students.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load both datasets into PySpark.\n",
        "# Print schema and infer nested structure.\n",
        "\n",
        "# Load CSV\n",
        "students_df = spark.read.csv(\"students.csv\", header=True, inferSchema=True)\n",
        "students_df.printSchema()\n",
        "students_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KorSLGpl0g5k",
        "outputId": "a3be5c56-1fb4-488a-9763-e8ee9611ec12"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+---+-----+----------+---------+------+\n",
            "| id| name|department|     city|salary|\n",
            "+---+-----+----------+---------+------+\n",
            "|  1| Amit|        IT|Bangalore| 78000|\n",
            "|  2|Kavya|        HR|  Chennai| 62000|\n",
            "|  3|Arjun|   Finance|Hyderabad| 55000|\n",
            "+---+-----+----------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON\n",
        "# Print schema and infer nested structure.\n",
        "emp_df = spark.read.json(\"employee_nested.json\", multiLine=True)\n",
        "emp_df.printSchema()\n",
        "emp_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DMTOUNe1REh",
        "outputId": "3e2cfc44-dfb9-452c-a3ba-5ef4ebb7f785"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- pincode: long (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+----------------+---+-----+---------------+\n",
            "|address         |id |name |skills         |\n",
            "+----------------+---+-----+---------------+\n",
            "|{Mumbai, 400001}|101|Sneha|[Python, Spark]|\n",
            "+----------------+---+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the JSON (use explode , select , alias ).\n",
        "from pyspark.sql.functions import explode, col\n",
        "\n",
        "flattened = emp_df.select(\n",
        "    \"id\",\n",
        "    \"name\",\n",
        "    col(\"address.city\").alias(\"City\"),\n",
        "    col(\"address.pincode\").alias(\"Pin-code\"),\n",
        "    explode(\"skills\").alias(\"Skill\")\n",
        ")\n",
        "flattened.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45YkafhR2C02",
        "outputId": "06d21949-7198-4c2c-de7b-2fa41d5e4a20"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+--------+------+\n",
            "| id| name|  City|Pin-code| Skill|\n",
            "+---+-----+------+--------+------+\n",
            "|101|Sneha|Mumbai|  400001|Python|\n",
            "|101|Sneha|Mumbai|  400001| Spark|\n",
            "+---+-----+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert both to Parquet and write to /tmp/output .\n",
        "students_df.write.mode(\"overwrite\").parquet(\"/tmp/output/students\")\n",
        "flattened.write.mode(\"overwrite\").parquet(\"/tmp/output/employees\")"
      ],
      "metadata": {
        "id": "QOGmeZoc2lda"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read students\n",
        "students_parquet = spark.read.parquet(\"/tmp/output/students\")\n",
        "students_parquet.show()\n",
        "\n",
        "# Read employees\n",
        "employees_parquet = spark.read.parquet(\"/tmp/output/employees\")\n",
        "employees_parquet.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS20BtIx3pJx",
        "outputId": "4b8acb43-6f96-420d-c569-cfd23c11c008"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+---------+------+\n",
            "| id| name|department|     city|salary|\n",
            "+---+-----+----------+---------+------+\n",
            "|  1| Amit|        IT|Bangalore| 78000|\n",
            "|  2|Kavya|        HR|  Chennai| 62000|\n",
            "|  3|Arjun|   Finance|Hyderabad| 55000|\n",
            "+---+-----+----------+---------+------+\n",
            "\n",
            "+---+-----+------+--------+------+\n",
            "| id| name|  City|Pin-code| Skill|\n",
            "+---+-----+------+--------+------+\n",
            "|101|Sneha|Mumbai|  400001|Python|\n",
            "|101|Sneha|Mumbai|  400001| Spark|\n",
            "+---+-----+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Spark SQL – Temp Views & Queries"
      ],
      "metadata": {
        "id": "yK2v6cnx-dRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5.1 Create view from exam scores and run:\n",
        "\n",
        "    a) Top scorer per subject\n",
        "    b) Count of students per grade\n",
        "    c) Students with multiple subjects\n",
        "    d) Subjects with average score above 85"
      ],
      "metadata": {
        "id": "f-kaeZoW-e8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create view from exam scores\n",
        "df_scores.createOrReplaceTempView(\"exam_scores\")"
      ],
      "metadata": {
        "id": "V9aMejfy4Geq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a) Top scorer per subject\n",
        "spark.sql(\"\"\"\n",
        "SELECT subject, name, MAX(score) as max_score\n",
        "FROM exam_scores\n",
        "GROUP BY subject, name\n",
        "ORDER BY max_score DESC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfsKPRky3sFx",
        "outputId": "aa066ad5-cbee-4b4c-f468-431d535f37fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+---------+\n",
            "|subject|  name|max_score|\n",
            "+-------+------+---------+\n",
            "|   Math|  Neha|       94|\n",
            "|Science|Ananya|       92|\n",
            "|   Math|  Ravi|       88|\n",
            "|Science| Meena|       85|\n",
            "|English| Kavya|       79|\n",
            "|English|  Ravi|       67|\n",
            "+-------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b) Count of students per grade\n",
        "spark.sql(\"\"\"\n",
        "SELECT grade, COUNT(*) as student_count\n",
        "FROM exam_scores\n",
        "GROUP BY grade\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duqDZbfi3y8j",
        "outputId": "8a163da8-0d86-49e1-f200-9f605fc38e21"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------+\n",
            "|grade|student_count|\n",
            "+-----+-------------+\n",
            "|    B|            2|\n",
            "|    C|            1|\n",
            "|    A|            2|\n",
            "|    D|            1|\n",
            "+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c) Students with multiple subjects\n",
        "spark.sql(\"\"\"\n",
        "SELECT name, COUNT(DISTINCT subject) as subject_count\n",
        "FROM exam_scores\n",
        "GROUP BY name\n",
        "HAVING subject_count > 1\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC97JkPr31o4",
        "outputId": "bbef3313-ee16-4fed-e5c8-0057ef4097f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|name|subject_count|\n",
            "+----+-------------+\n",
            "|Ravi|            2|\n",
            "+----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d) Subjects with average score above 85\n",
        "spark.sql(\"\"\"\n",
        "SELECT subject, AVG(score) as avg_score\n",
        "FROM exam_scores\n",
        "GROUP BY subject\n",
        "HAVING avg_score > 85\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUgqraai33QJ",
        "outputId": "21192387-2a52-4c97-d64e-7b57d30ecb37"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5.2 Create another DataFrame attendance(name, days_present) and:\n",
        "\n",
        "    Join with scores\n",
        "    \n",
        "    Calculate attendance-adjusted grade:\n",
        "    If days_present < 20 → downgrade grade by one level"
      ],
      "metadata": {
        "id": "0UfJEy9Y-rhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create another DataFrame attendance(name, days_present)\n",
        "attendance = [(\"Ravi\", 18), (\"Ananya\", 22), (\"Kavya\", 25), (\"Neha\", 15), (\"Meena\", 20)]\n",
        "attendance_df = spark.createDataFrame(attendance, [\"name\", \"days_present\"])"
      ],
      "metadata": {
        "id": "TFyfh6j044E-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join with scores\n",
        "joined_df = df_scores.join(attendance_df, \"name\")"
      ],
      "metadata": {
        "id": "tLNV9lmV5Eal"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate attendance-adjusted grade:\n",
        "# If days_present < 20 → downgrade grade by one level\n",
        "\n",
        "# Downgrade logic\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "joined_df = joined_df.withColumn(\n",
        "    \"adjusted_grade\",\n",
        "    when(col(\"days_present\") < 20,\n",
        "         expr(\"\"\"CASE grade\n",
        "                 WHEN 'A' THEN 'B'\n",
        "                 WHEN 'B' THEN 'C'\n",
        "                 WHEN 'C' THEN 'D'\n",
        "                 ELSE 'D' END\"\"\"))\n",
        "    .otherwise(col(\"grade\"))\n",
        ")\n",
        "\n",
        "joined_df.select(\"name\", \"subject\", \"score\", \"grade\", \"days_present\", \"adjusted_grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4wIcB0C5Hl8",
        "outputId": "60272cb0-df4c-4c72-fc53-3aa5b7675871"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+------------+--------------+\n",
            "|  name|subject|score|grade|days_present|adjusted_grade|\n",
            "+------+-------+-----+-----+------------+--------------+\n",
            "|Ananya|Science|   92|    A|          22|             A|\n",
            "| Kavya|English|   79|    C|          25|             C|\n",
            "| Meena|Science|   85|    B|          20|             B|\n",
            "|  Neha|   Math|   94|    A|          15|             B|\n",
            "|  Ravi|   Math|   88|    B|          18|             C|\n",
            "|  Ravi|English|   67|    D|          18|             D|\n",
            "+------+-------+-----+-----+------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Partitioned Load (Full + Incremental)"
      ],
      "metadata": {
        "id": "E1Aj0d9Y-_Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Load:\n",
        "df_scores.write.partitionBy(\"subject\").parquet(\"/tmp/scores/\", mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "bi938xHg5SoD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incremental Load:\n",
        "incremental = [(\"Meena\", \"Math\", 93)]\n",
        "df_inc = spark.createDataFrame(incremental, columns)\n",
        "df_inc.write.mode(\"append\").partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "M62CwyyP5Xpg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task:\n",
        "\n",
        "    List all folders inside /tmp/scores/\n",
        "\n",
        "    Read only Math partition and display all entries."
      ],
      "metadata": {
        "id": "nJZhv_JN_DyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all folders inside /tmp/scores/\n",
        "!ls /tmp/scores/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMWkSS2F5bqi",
        "outputId": "a889e777-9759-4b90-fcd5-654762af26ab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'subject=English'  'subject=Math'  'subject=Science'   _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read only Math partition and display all entries.\n",
        "math_df = spark.read.parquet(\"/tmp/scores/subject=Math\")\n",
        "math_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5ayw9lT5hJE",
        "outputId": "734bf9c8-027d-4a57-c7ca-b8d1c36e764a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+----------+----+----------+\n",
            "| name|score|grade|difficulty|rank|name_upper|\n",
            "+-----+-----+-----+----------+----+----------+\n",
            "| Neha|   94|    A| Difficult|   1|      NEHA|\n",
            "| Ravi|   88|    B| Difficult|   2|      RAVI|\n",
            "|Meena|   93| NULL|      NULL|NULL|      NULL|\n",
            "+-----+-----+-----+----------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. ETL: Clean, Transform, Load"
      ],
      "metadata": {
        "id": "ivnpBC1O_IpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "umbRDBw87O74",
        "outputId": "fd47c5ab-2508-405a-e172-14af82aa615c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c59d7416-0cb3-4b10-b1f7-8eca86e40b6f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c59d7416-0cb3-4b10-b1f7-8eca86e40b6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving employee_raw.csv to employee_raw.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "    Load data with header.\n",
        "\n",
        "    Fill missing bonus with 2000.\n",
        "\n",
        "    Calculate total_ctc = salary + bonus .\n",
        "\n",
        "    Filter where total_ctc > 60,000.\n",
        "\n",
        "    Save final DataFrame to Parquet and JSON."
      ],
      "metadata": {
        "id": "-j1Qoxd-_MGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data with header.\n",
        "raw_df = spark.read.csv(\"employee_raw.csv\", header=True, inferSchema=True)\n",
        "raw_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9iBb3JY6OW1",
        "outputId": "a4b313ab-c240-40cb-9692-0597d72e68a9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+\n",
            "|emp_id| name|   dept|salary|bonus|\n",
            "+------+-----+-------+------+-----+\n",
            "|     1|Arjun|     IT| 78000| 5000|\n",
            "|     2|Kavya|     HR| 62000| NULL|\n",
            "|     3|Sneha|Finance| 55000| 3000|\n",
            "+------+-----+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing bonus with 2000.\n",
        "from pyspark.sql.functions import coalesce, lit\n",
        "\n",
        "clean_df = raw_df.withColumn(\"bonus\", coalesce(col(\"bonus\"), lit(2000)))\n",
        "clean_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB-uyTe-6QW_",
        "outputId": "c06c108a-4fe8-42f9-a70e-a61af9721cd7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+\n",
            "|emp_id| name|   dept|salary|bonus|\n",
            "+------+-----+-------+------+-----+\n",
            "|     1|Arjun|     IT| 78000| 5000|\n",
            "|     2|Kavya|     HR| 62000| 2000|\n",
            "|     3|Sneha|Finance| 55000| 3000|\n",
            "+------+-----+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total_ctc = salary + bonus .\n",
        "clean_df = clean_df.withColumn(\"total_ctc\", col(\"salary\") + col(\"bonus\"))\n",
        "clean_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i5ZB9Ws6Sn2",
        "outputId": "50b0b910-75d1-4d7b-c5d2-1846324978ba"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 78000| 5000|    83000|\n",
            "|     2|Kavya|     HR| 62000| 2000|    64000|\n",
            "|     3|Sneha|Finance| 55000| 3000|    58000|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter where total_ctc > 60,000.\n",
        "filtered_df = clean_df.filter(col(\"total_ctc\") > 60000)\n",
        "filtered_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StFTMwuY6U2s",
        "outputId": "e8a8ecf3-7e67-44d6-b61d-5ba04fe50284"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+----+------+-----+---------+\n",
            "|emp_id| name|dept|salary|bonus|total_ctc|\n",
            "+------+-----+----+------+-----+---------+\n",
            "|     1|Arjun|  IT| 78000| 5000|    83000|\n",
            "|     2|Kavya|  HR| 62000| 2000|    64000|\n",
            "+------+-----+----+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final DataFrame to Parquet and JSON.\n",
        "filtered_df.write.mode(\"overwrite\").parquet(\"/tmp/clean_employees/parquet\")\n",
        "filtered_df.write.mode(\"overwrite\").json(\"/tmp/clean_employees/json\")"
      ],
      "metadata": {
        "id": "NIUCDs796Utq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and Show Parquet Files\n",
        "parquet_df = spark.read.parquet(\"/tmp/clean_employees/parquet\")\n",
        "parquet_df.toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "K9Bf14DS8EUA",
        "outputId": "50290528-303f-44f8-bb46-ef12da750af6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emp_id   name dept  salary  bonus  total_ctc\n",
              "0       1  Arjun   IT   78000   5000      83000\n",
              "1       2  Kavya   HR   62000   2000      64000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-159851ae-f4af-478a-be4c-692d995e9496\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emp_id</th>\n",
              "      <th>name</th>\n",
              "      <th>dept</th>\n",
              "      <th>salary</th>\n",
              "      <th>bonus</th>\n",
              "      <th>total_ctc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Arjun</td>\n",
              "      <td>IT</td>\n",
              "      <td>78000</td>\n",
              "      <td>5000</td>\n",
              "      <td>83000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Kavya</td>\n",
              "      <td>HR</td>\n",
              "      <td>62000</td>\n",
              "      <td>2000</td>\n",
              "      <td>64000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-159851ae-f4af-478a-be4c-692d995e9496')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-159851ae-f4af-478a-be4c-692d995e9496 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-159851ae-f4af-478a-be4c-692d995e9496');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d8ab661-f003-4fe7-88a0-890c236afca0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d8ab661-f003-4fe7-88a0-890c236afca0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d8ab661-f003-4fe7-88a0-890c236afca0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"parquet_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"emp_id\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Kavya\",\n          \"Arjun\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dept\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"HR\",\n          \"IT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          62000,\n          78000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bonus\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2000,\n          5000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_ctc\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          64000,\n          83000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/tmp/clean_employees/json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8usaU9Y8-6k",
        "outputId": "af8263a7-b1e8-47d6-832d-148bea0652e6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['._SUCCESS.crc',\n",
              " '.part-00000-c66136e0-f048-4851-a269-044d3812f61e-c000.json.crc',\n",
              " '_SUCCESS',\n",
              " 'part-00000-c66136e0-f048-4851-a269-044d3812f61e-c000.json']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download JSON file\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Rename the file\n",
        "os.rename(\"/tmp/clean_employees/json/part-00000-c66136e0-f048-4851-a269-044d3812f61e-c000.json\",\n",
        "          \"/tmp/cleaned_employees.json\")\n",
        "\n",
        "# Download the renamed file\n",
        "files.download(\"/tmp/cleaned_employees.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PAFrQgYm8IEY",
        "outputId": "eb901f11-3d79-4bc9-9441-8f3639ca0387"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c62491dc-16a1-43ff-adae-3d56c28f78ed\", \"cleaned_employees.json\", 172)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}